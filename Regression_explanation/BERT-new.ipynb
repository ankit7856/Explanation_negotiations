{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom dataset class\n",
    "class ExplanationDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.labels = dataframe['confidence_score'].values\n",
    "        self.texts = dataframe['explanation'].values\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx], truncation=True, padding='max_length', max_length=512)\n",
    "        item = {key: torch.tensor(val) for key, val in encoding.items()}\n",
    "        # Regression requires float labels\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "# Function to train the model on the entire dataset\n",
    "def train_model(df, model_name):\n",
    "    # Use the entire dataset for training\n",
    "    train_dataset = ExplanationDataset(df)\n",
    "\n",
    "    # Load the custom BERT model for regression\n",
    "    model = BertForRegression()\n",
    "\n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'./results_{model_name}',\n",
    "        num_train_epochs=10,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=f'./logs_{model_name}',\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"no\",  # No evaluation steps since we're training on the full dataset\n",
    "        save_steps=100,\n",
    "        save_total_limit=2,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Save the model and tokenizer\n",
    "    torch.save(model.state_dict(), f'bert-finetuned-{model_name}.pt')\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    tokenizer.save_pretrained(f'bert-finetuned-{model_name}')\n",
    "\n",
    "# Load the datasets from the provided CSV files\n",
    "df_layperson = pd.read_csv('layperson_explanation_dataset.csv')\n",
    "df_expert = pd.read_csv('expert_explanation_dataset.csv')\n",
    "\n",
    "# Train the model for layperson explanations\n",
    "train_model(df_layperson, 'layperson')\n",
    "\n",
    "# Train the model for expert explanations\n",
    "train_model(df_expert, 'expert')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, TextClassificationPipeline\n",
    "\n",
    "openai.api_key = 'sk-proj-eCKWxtFXUDb0yThKFtx1T3BlbkFJXvgHaR4d455KUPYGVi4L'\n",
    "\n",
    "# Generating enriched explanation from mathematical sentence\n",
    "domain = (\n",
    "    \"two agents representing two people living together while organizing a party negotiate over 6 issues: \"\n",
    "    \"the food type, drinks type, location, type of invitations, music, and the clean-up service. Each issue \"\n",
    "    \"further consists of 3 to 5 values, resulting in a domain with 3072 total possible outcomes.\"\n",
    ")\n",
    "\n",
    "def enrich_explanation(sentence):\n",
    "    \n",
    "    prompt = (\n",
    "        f\"Provide a clear and concise explanation of the following statement in just 1 or 2 lines. Consider the domain context:\\n\\n\"\n",
    "        f\"{domain}\\n\\n\"\n",
    "        f\"Statement: {sentence}\\n\\nExplanation:\"\n",
    "    )\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You're an expert assistant who provides clear and concise explanation\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=400,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0,\n",
    "    )\n",
    "\n",
    "    enriched_explanation = response['choices'][0]['message']['content'].strip()\n",
    "    return enriched_explanation\n",
    "\n",
    "\n",
    "sentence = r\"Ensures \\(U_u(\\omega_t^o) \\) meets either a calculated statistical value or a specified minimum utility requirement in the initial interval \\( [0.000, 0.0361) \\)\"\n",
    "enriched_sentence = enrich_explanation(sentence)\n",
    "print(f\"Enriched Explanation:\\n{enriched_sentence}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_layperson(enriched_sentence):\n",
    "    return (\n",
    "        \"Your task is to explain the following mathematical statement in very simple terms, suitable for someone without any technical background. The explanation should be clear, concise, and within 30 words. Avoid using any jargon or complex terms. Refer to the examples below for the style of explanation:\\n\\n\"\n",
    "        f\"**Mathematical Statement:**\\n{enriched_sentence}\\n\\n\"\n",
    "        \"**Examples of Clear Explanations for a Layperson:**\\n\"\n",
    "        \"1. The final price should match the average market price or include a discount, ensuring it is fair and competitive.\\n\"\n",
    "        \"2. In the first phase, the plan should improve basic features to be at least as good as a standard option.\\n\"\n",
    "        \"3. The service package should meet a basic quality level or reach a specific customer satisfaction score to ensure a good experience.\\n\"\n",
    "        \"4. The initial budget must be large enough to cover all estimated costs and any additional expenses.\\n\\n\"\n",
    "        \"**Your Task:**\\n\"\n",
    "        \"Based on the mathematical statement provided, generate a clear and simple explanation suitable for a layperson, within 50 words.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Prompt for expert explanation\n",
    "\n",
    "\n",
    "def prompt_expert(enriched_sentence):\n",
    "    return (\n",
    "        \"Provide a detailed and technical explanation of the following mathematical statement for a domain expert. The explanation should be within 50 words. Refer to the examples below for the style of explanation:\\n\\n\"\n",
    "        f\"**Mathematical Statement:**\\n{enriched_sentence}\\n\\n\"\n",
    "        \"**Explanation for Domain Expert:**\\n\"\n",
    "        \"1. During the second interval [0.0361, 1.000], the utility of the opponent's offer \\( U_u(\\omega_t^o) \\) must exceed the higher of a predefined threshold \\( u \\) or the quantile function \\( U_{\\Omega^o_t} \\) at a specific time-dependent point.\\n\"\n",
    "        \"2. The initial evaluation phase requires the service package value \\( V_s \\) to surpass the minimum quality benchmark or meet a defined satisfaction threshold to ensure compliance with service standards.\\n\"\n",
    "        \"3. The order quantity \\( Q_s \\) must align with the highest value between the minimum stock level and a demand forecast quantile to optimize inventory management during the initial stocking phase.\\n\\n\"\n",
    "        \"**Your Task:**\\n\"\n",
    "        \"Provide a similar style explanation suitable for an expert, within 50 words.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_explanation(sentence, target_audience, prompt_func, confidence_score=None, max_tokens=400, temperature=0.6, top_p=0.7, frequency_penalty=0.0, presence_penalty=0.0):\n",
    "    # Generate the initial prompt based on the target audience\n",
    "    prompt = prompt_func(enriched_sentence)\n",
    "\n",
    "    # If confidence_score is provided, generate feedback\n",
    "    if confidence_score is not None:\n",
    "        feedback = generate_feedback(\n",
    "            enriched_sentence, confidence_score, target_audience)\n",
    "        prompt += f\"\\n\\nFeedback for Improvement:\\n{feedback}\\n\\nRefine the explanation based on the feedback.\"\n",
    "    else:\n",
    "        feedback = None\n",
    "\n",
    "    # Use OpenAI's API to get the explanation\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert assistant. Your task is to provide clear and concise explanations for the specified audience.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty,\n",
    "    )\n",
    "\n",
    "    # Extract the custom explanation from the response\n",
    "    custom_explanation = response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "    # Check if the response is close to the token limit and add a note if it is\n",
    "    if len(custom_explanation) >= max_tokens - 20:\n",
    "        custom_explanation += \" (response cut off, please refine or increase token limit)\"\n",
    "\n",
    "    return custom_explanation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned models after additional training\n",
    "layperson_model = BertForRegression()\n",
    "layperson_model.load_state_dict(torch.load('bert-finetuned-layperson.pt'))\n",
    "layperson_tokenizer = BertTokenizer.from_pretrained('bert-finetuned-layperson')\n",
    "\n",
    "expert_model = BertForRegression()\n",
    "expert_model.load_state_dict(torch.load('bert-finetuned-expert.pt'))\n",
    "expert_tokenizer = BertTokenizer.from_pretrained('bert-finetuned-expert')\n",
    "\n",
    "# Function to validate an explanation using the appropriate model and tokenizer\n",
    "def validate_explanation(explanation, target_audience, max_length=512):\n",
    "    if target_audience == 'layperson':\n",
    "        model = layperson_model\n",
    "        tokenizer = layperson_tokenizer\n",
    "    elif target_audience == 'expert':\n",
    "        model = expert_model\n",
    "        tokenizer = expert_tokenizer\n",
    "    else:\n",
    "        raise ValueError(\"Invalid target audience. Choose either 'layperson' or 'expert'.\")\n",
    "\n",
    "    model.eval()\n",
    "    inputs = tokenizer(explanation, return_tensors=\"pt\",\n",
    "                       truncation=True, padding='max_length', max_length=max_length)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Directly use the regression output (already in [0, 1] range due to sigmoid)\n",
    "    confidence_score = outputs.item()\n",
    "    \n",
    "    return confidence_score\n",
    "\n",
    "# Function to generate feedback based on the confidence score and target audience\n",
    "def generate_feedback(explanation, confidence_score, target_audience):\n",
    "    feedback = \"\"\n",
    "\n",
    "    if target_audience == 'layperson':\n",
    "        if confidence_score < 0.4:\n",
    "            feedback = \"The explanation is too complex and difficult for a layperson to understand. Simplify the language, remove technical terms, and use more relatable examples.\"\n",
    "        elif 0.4 <= confidence_score < 0.7:\n",
    "            feedback = \"The explanation is somewhat clear but could be improved. Consider simplifying the language further and ensuring it is more engaging for a layperson.\"\n",
    "        elif confidence_score >= 0.7:\n",
    "            feedback = \"The explanation is clear and easy to understand. It's well-suited for a layperson, but consider making it even more engaging or concise.\"\n",
    "    elif target_audience == 'expert':\n",
    "        if confidence_score < 0.4:\n",
    "            feedback = \"The explanation lacks the necessary technical depth and detail for an expert. Include more precise terms, context, and relevant details to improve it.\"\n",
    "        elif 0.4 <= confidence_score < 0.7:\n",
    "            feedback = \"The explanation is somewhat detailed but could benefit from additional technical depth. Ensure all relevant information is included and accurately presented.\"\n",
    "        elif confidence_score >= 0.7:\n",
    "            feedback = \"The explanation is detailed and technically sound, making it well-suited for an expert audience. You might consider adding even more technical depth if appropriate.\"\n",
    "\n",
    "    return feedback\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get user choice\n",
    "def get_user_choice():\n",
    "    while True:\n",
    "        choice = input(\n",
    "            \"Choose the target audience (layperson/expert): \").strip().lower()\n",
    "        if choice in ['layperson', 'expert']:\n",
    "            return choice\n",
    "        else:\n",
    "            print(\"Invalid choice. Please enter 'layperson' or 'expert'.\")\n",
    "\n",
    "\n",
    "# Layperson threshold (you might want to adjust this if you're doing expert explanations)\n",
    "threshold = 0.7\n",
    "\n",
    "# Get the user's choice for target audience\n",
    "target_audience = get_user_choice()\n",
    "\n",
    "# Loop until explanation meets the threshold for the chosen audience\n",
    "explanation = \"\"\n",
    "feedback = \"\"\n",
    "while True:\n",
    "    explanation = custom_explanation(\n",
    "        enriched_sentence, target_audience, prompt_layperson if target_audience == 'layperson' else prompt_expert, max_tokens=400, temperature=0.7, top_p=1.0,)\n",
    "\n",
    "    # Output the generated explanation\n",
    "    print(f\"Generated Explanation for {target_audience}:\\n{explanation}\\n\")\n",
    "\n",
    "    score = validate_explanation(explanation, target_audience)\n",
    "\n",
    "    # Output the confidence score\n",
    "    print(f\"Confidence Score: {score}\\n\")\n",
    "\n",
    "    feedback = generate_feedback(explanation, score, target_audience)\n",
    "\n",
    "    if score >= threshold:\n",
    "        print(\n",
    "            f\"Final Explanation for {target_audience} based on enriched sentence:\\n\\n{explanation}\\n\")\n",
    "        break\n",
    "    else:\n",
    "        print(f\"{target_audience.capitalize()} explanation below threshold with score {score}, refining... Feedback: {feedback}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
