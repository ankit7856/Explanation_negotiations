{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the mixed dataset\n",
    "df_mixed_new = pd.read_csv('merged_shuffled_dataset.csv')\n",
    "\n",
    "# Check the initial target audience distribution for verification\n",
    "print(\"Initial target audience distribution:\\n\", df_mixed_new['target_audience'].value_counts())\n",
    "\n",
    "# Correctly encode target labels using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df_mixed_new['target_label'] = label_encoder.fit_transform(df_mixed_new['target_audience'])\n",
    "\n",
    "# Verify the label encoding\n",
    "print(\"Label encoding classes:\", label_encoder.classes_)  # This should output ['expert' 'layperson']\n",
    "print(\"Encoded labels distribution:\\n\", df_mixed_new['target_label'].value_counts())\n",
    "\n",
    "# Check the actual encodings to ensure correctness\n",
    "encoded_expert = label_encoder.transform(['expert'])[0]\n",
    "encoded_layperson = label_encoder.transform(['layperson'])[0]\n",
    "print(f\"Encoded 'expert' as: {encoded_expert}\")  # Expected: 0\n",
    "print(f\"Encoded 'layperson' as: {encoded_layperson}\")  # Expected: 1\n",
    "\n",
    "# Define the custom dataset class\n",
    "class ExplanationDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.labels = dataframe['target_label'].values\n",
    "        self.texts = dataframe['explanation'].values\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx], truncation=True, padding='max_length', max_length=512\n",
    "        )\n",
    "        item = {key: torch.tensor(val) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)  # Classification requires long tensor\n",
    "        return item\n",
    "\n",
    "# Function to train a model\n",
    "def train_model(df, model_name):\n",
    "    # Split the dataset into train and validation sets\n",
    "    train_size = int(0.8 * len(df))\n",
    "    val_size = len(df) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        ExplanationDataset(df), [train_size, val_size]\n",
    "    )\n",
    "\n",
    "    # Load BERT model for classification\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        'bert-base-uncased', num_labels=len(label_encoder.classes_)\n",
    "    )\n",
    "\n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'./results_{model_name}',\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=f'./logs_{model_name}',\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"epoch\",  \n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=2,\n",
    "        load_best_model_at_end=True,  \n",
    "        metric_for_best_model=\"eval_loss\", \n",
    "        logging_first_step=True\n",
    "    )\n",
    "\n",
    "    # Initialize the Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Save the model and tokenizer\n",
    "    model.save_pretrained(f'bert-finetuned-{model_name}')\n",
    "    tokenizer.save_pretrained(f'bert-finetuned-{model_name}')\n",
    "\n",
    "# Train the model on the mixed dataset\n",
    "train_model(df_mixed_new, 'Nego_BERT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cim/pgt/mmac292/Dissertation/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enriched Explanation:\n",
      "The statement means that the utility value \\(U_u(\\omega_t^o) \\) should meet either a predetermined statistical value or a minimum utility threshold in the initial range of 0.000 to 0.0361.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, TextClassificationPipeline\n",
    "\n",
    "load_dotenv() \n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "\n",
    "# Generating enriched explanation from mathematical sentence\n",
    "domain = (\n",
    "    \"two agents representing two people living together while organizing a party negotiate over 6 issues: \"\n",
    "    \"the food type, drinks type, location, type of invitations, music, and the clean-up service. Each issue \"\n",
    "    \"further consists of 3 to 5 values, resulting in a domain with 3072 total possible outcomes.\"\n",
    ")\n",
    "\n",
    "def enrich_explanation(sentence):\n",
    "    \n",
    "    prompt = (\n",
    "        f\"Provide a clear and concise explanation of the following statement in just 1 or 2 lines. Consider the domain context:\\n\\n\"\n",
    "        f\"{domain}\\n\\n\"\n",
    "        f\"Statement: {sentence}\\n\\nExplanation:\"\n",
    "    )\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You're an expert assistant who provides clear and concise explanation\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=400,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0,\n",
    "    )\n",
    "\n",
    "    enriched_explanation = response['choices'][0]['message']['content'].strip()\n",
    "    return enriched_explanation\n",
    "\n",
    "\n",
    "sentence = r\"Ensures \\(U_u(\\omega_t^o) \\) meets either a calculated statistical value or a specified minimum utility requirement in the initial interval \\( [0.000, 0.0361) \\)\"\n",
    "enriched_sentence = enrich_explanation(sentence)\n",
    "print(f\"Enriched Explanation:\\n{enriched_sentence}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_layperson(enriched_sentence):\n",
    "    return (\n",
    "        \"Your task is to explain the following mathematical statement in very simple terms, suitable for someone without any technical background. The explanation should be clear, concise, and within 30 words. Avoid using any jargon or complex terms. Refer to the examples below for the style of explanation:\\n\\n\"\n",
    "        f\"**Mathematical Statement:**\\n{enriched_sentence}\\n\\n\"\n",
    "        \"**Examples of Clear Explanations for a Layperson:**\\n\"\n",
    "        \"1. The final price should match the average market price or include a discount, ensuring it is fair and competitive.\\n\"\n",
    "        \"2. In the first phase, the plan should improve basic features to be at least as good as a standard option.\\n\"\n",
    "        \"3. The service package should meet a basic quality level or reach a specific customer satisfaction score to ensure a good experience.\\n\"\n",
    "        \"4. The initial budget must be large enough to cover all estimated costs and any additional expenses.\\n\\n\"\n",
    "        \"**Your Task:**\\n\"\n",
    "        \"Based on the mathematical statement provided, generate a clear and simple explanation suitable for a layperson, within 50 words.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Prompt for expert explanation\n",
    "\n",
    "\n",
    "def prompt_expert(enriched_sentence):\n",
    "    return (\n",
    "        \"Provide a detailed and technical explanation of the following mathematical statement for a domain expert. The explanation should be within 50 words. Refer to the examples below for the style of explanation:\\n\\n\"\n",
    "        f\"**Mathematical Statement:**\\n{enriched_sentence}\\n\\n\"\n",
    "        \"**Explanation for Domain Expert:**\\n\"\n",
    "        \"1. During the second interval [0.0361, 1.000], the utility of the opponent's offer \\( U_u(\\omega_t^o) \\) must exceed the higher of a predefined threshold \\( u \\) or the quantile function \\( U_{\\Omega^o_t} \\) at a specific time-dependent point.\\n\"\n",
    "        \"2. The initial evaluation phase requires the service package value \\( V_s \\) to surpass the minimum quality benchmark or meet a defined satisfaction threshold to ensure compliance with service standards.\\n\"\n",
    "        \"3. The order quantity \\( Q_s \\) must align with the highest value between the minimum stock level and a demand forecast quantile to optimize inventory management during the initial stocking phase.\\n\\n\"\n",
    "        \"**Your Task:**\\n\"\n",
    "        \"Provide a similar style explanation suitable for an expert, within 50 words.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_explanation(sentence, target_audience, prompt_func, confidence_score=None, max_tokens=400, temperature=0.6, top_p=0.7, frequency_penalty=0.0, presence_penalty=0.0):\n",
    "    # Generate the initial prompt based on the target audience\n",
    "    prompt = prompt_func(enriched_sentence)\n",
    "\n",
    "    # If confidence_score is provided, generate feedback\n",
    "    if confidence_score is not None:\n",
    "        feedback = generate_feedback(\n",
    "            enriched_sentence, confidence_score, target_audience)\n",
    "        prompt += f\"\\n\\nFeedback for Improvement:\\n{feedback}\\n\\nRefine the explanation based on the feedback.\"\n",
    "    else:\n",
    "        feedback = None\n",
    "\n",
    "    # Use OpenAI's API to get the explanation\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert assistant. Your task is to provide clear and concise explanations for the specified audience.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty,\n",
    "    )\n",
    "\n",
    "    # Extract the custom explanation from the response\n",
    "    custom_explanation = response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "    # Check if the response is close to the token limit and add a note if it is\n",
    "    if len(custom_explanation) >= max_tokens - 20:\n",
    "        custom_explanation += \" (response cut off, please refine or increase token limit)\"\n",
    "\n",
    "    return custom_explanation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Load the fine-tuned BERT model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained('bert-finetuned-Nego_BERT')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-finetuned-Nego_BERT')\n",
    "\n",
    "# Function to get user's choice for the target audience\n",
    "def get_user_choice():\n",
    "    while True:\n",
    "        choice = input(\"Choose the target audience (layperson/expert): \").strip().lower()\n",
    "        if choice in ['layperson', 'expert']:\n",
    "            return choice\n",
    "        else:\n",
    "            print(\"Invalid choice. Please enter 'layperson' or 'expert'.\")\n",
    "\n",
    "# Function to validate an explanation using the trained BERT model and return confidence score\n",
    "def validate_explanation(explanation, intended_audience, max_length=512):\n",
    "    try:\n",
    "        # Ensure the model is in evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # Tokenize the input explanation\n",
    "        inputs = tokenizer(explanation, return_tensors=\"pt\",\n",
    "                           truncation=True, padding='max_length', max_length=max_length)\n",
    "\n",
    "        # Predict the target audience\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        # Get the logits and apply softmax to get probabilities\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        predicted_label = torch.argmax(probs, dim=1).item()\n",
    "        confidence = probs.max().item()  # Get the confidence score of the prediction\n",
    "\n",
    "        # Convert predicted label back to the target audience (0 for expert, 1 for layperson)\n",
    "        predicted_audience = 'expert' if predicted_label == 0 else 'layperson'\n",
    "        \n",
    "        return predicted_audience, confidence\n",
    "    except Exception as e:\n",
    "        print(f\"Error in validate_explanation: {e}\")\n",
    "        return None, 0.0  # Return zero confidence on error\n",
    "\n",
    "# Function to generate feedback based on the intended and predicted audience\n",
    "def generate_feedback(explanation, predicted_audience, target_audience):\n",
    "    if predicted_audience == target_audience:\n",
    "        return f\"The explanation is suitable for a {target_audience}.\"\n",
    "    else:\n",
    "        return (f\"The explanation is not suitable for a {target_audience}. \"\n",
    "                f\"Please improve it to better match the needs of a {target_audience}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Explanation for layperson:\n",
      "The value we're looking at should either match a set standard or be above a certain low point, within a specific small range from 0.000 to 0.0361.\n",
      "\n",
      "Predicted Audience: layperson, Confidence Score: 0.98\n",
      "Final Explanation for layperson based on enriched sentence:\n",
      "\n",
      "The value we're looking at should either match a set standard or be above a certain low point, within a specific small range from 0.000 to 0.0361.\n",
      "Confidence Score: 0.98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get user's choice for target audience\n",
    "target_audience = get_user_choice()\n",
    "\n",
    "# Loop until the explanation is suitable for the target audience\n",
    "while True:\n",
    "    # Generate a custom explanation (assuming you have this function defined)\n",
    "    explanation = custom_explanation(\n",
    "        enriched_sentence, target_audience, \n",
    "        prompt_layperson if target_audience == 'layperson' else prompt_expert, \n",
    "    )\n",
    "\n",
    "    print(f\"Generated Explanation for {target_audience}:\\n{explanation}\\n\")\n",
    "\n",
    "    # Validate the explanation with the model and get confidence score\n",
    "    predicted_audience, confidence = validate_explanation(explanation, target_audience)\n",
    "\n",
    "    if predicted_audience is None:\n",
    "        print(\"Failed to validate the explanation. Please try again.\")\n",
    "        continue\n",
    "\n",
    "    # Generate feedback based on the prediction\n",
    "    feedback = generate_feedback(explanation, predicted_audience, target_audience)\n",
    "\n",
    "    # Print confidence score\n",
    "    print(f\"Predicted Audience: {predicted_audience}, Confidence Score: {confidence:.2f}\")\n",
    "\n",
    "    if predicted_audience == target_audience:\n",
    "        print(\n",
    "            f\"Final Explanation for {target_audience} based on enriched sentence:\\n\\n{explanation}\\n\"\n",
    "            f\"Confidence Score: {confidence:.2f}\\n\")\n",
    "        break\n",
    "    else:\n",
    "        print(f\"Explanation not suitable for {target_audience}. Feedback: {feedback}\\nRefining explanation...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
